# WARNING:
# if your dataset has too many items and you dont't have enough GPU memory to evaluate it
# by using full sort, you should set 'split_to' > 0 and try again. Otherwise, you should
# set 'split_to'=0 which has the fastest speed.

embedding_size: 64
# when evaluate the model by full sort, one user will be divide into the number of slices you set
split_to: 0
reg_weights: [1e-2, 1e-2]
alpha: 0