# Type of training method
convert_token_to_onehot: False
token_num_threshold: 10000

# DMatrix
xgb_weight: ~
xgb_base_margin: ~
xgb_missing: ~
xgb_silent: ~
xgb_feature_names: ~
xgb_feature_types: ~
xgb_nthread: ~

xgb_model: ~
xgb_params: 
    booster: gbtree
    objective: binary:logistic
    eval_metric: ['auc','logloss']
    # gamma: 0.1
    max_depth: 3
    # lambda: 1
    # subsample: 0.7
    # colsample_bytree: 0.7
    # min_child_weight: 3
    eta: 1
    seed: 2020
    # nthread: -1
xgb_num_boost_round: 500
# xgb_evals: ~
xgb_obj: ~
xgb_feval: ~
xgb_maximize: ~
xgb_early_stopping_rounds: ~
# xgb_evals_result: ~
xgb_verbose_eval: 100

