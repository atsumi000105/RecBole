[model]

# algorithm=prod
algorithm=concat
# if pretrain is not None, the module will use pretrin, and maybe you should run this module twice
train_type='pretrain'
# train_type='retrain'
embedding_size=64
weight_size=64
regs=[1e-7, 1e-7, 1e-5]
alpha=0
beta=0.5